{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import heapq\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import loglikelihood\n",
    "import nltk\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dir_if_doesnt_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "YEAR = 2009\n",
    "PATH = 'F:\\\\saos\\\\data\\\\json\\\\judgments-*'\n",
    "HELPERS_DIR = 'helpers'\n",
    "\n",
    "create_dir_if_doesnt_exist(HELPERS_DIR)\n",
    "\n",
    "FILENAMES_FOR_YEAR = os.path.join(HELPERS_DIR, f'judgments_from_{YEAR}.json')\n",
    "WORD_COUNTS_FILENAME = os.path.join(HELPERS_DIR, 'counts.json')\n",
    "BIGRAMS_COUNTS_FILENAME = os.path.join(HELPERS_DIR, 'bigrams_counts.json')\n",
    "NUMBER_OF_RESULTS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year_pattern = str(YEAR) + '-\\d{2}-\\d{2}'\n",
    "\n",
    "def get_filenames_with_judgments_for_year(judgment_filenames):\n",
    "    with open(FILENAMES_FOR_YEAR, 'w') as file:\n",
    "        filenames_for_year = filter(contains_judgments_from_year, judgment_filenames)\n",
    "        json.dump(list(filenames_for_year), file)\n",
    "\n",
    "\n",
    "def contains_judgments_from_year(filename):\n",
    "    return any(re.match(year_pattern, item['judgmentDate']) for item in get_judgments(filename))\n",
    "\n",
    "\n",
    "def get_judgments(filename):\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        content = json.load(file)\n",
    "    return (item for item in content['items'] if re.match(year_pattern, item['judgmentDate']))\n",
    "\n",
    "\n",
    "def clear_text(text: str):\n",
    "    return re.sub('-\\n', '', BeautifulSoup(text).get_text())\n",
    "\n",
    "\n",
    "def tokenize_and_filter(text):\n",
    "    yield from filter(is_word, map(str.lower, nltk.word_tokenize(text, language='polish')))\n",
    "\n",
    "\n",
    "def is_vowel(letter):\n",
    "    return letter in ('a', 'ą', 'e', 'ę', 'i', 'o', 'ó', 'u', 'y')\n",
    "\n",
    "\n",
    "def is_word(word: str):\n",
    "    return word.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_words(texts):\n",
    "    for judgment_text in texts:\n",
    "        yield from tokenize_and_filter(judgment_text)\n",
    "\n",
    "\n",
    "def generate_bigrams(texts):\n",
    "    yield from nltk.bigrams(generate_words(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pointwise_mutual_information(bigram, *, word_counter, bigrams_counter, words_count, bigrams_count):\n",
    "    first_word, second_word = bigram\n",
    "    bigram_prob = bigrams_counter[bigram] / bigrams_count\n",
    "    first_word_prob = word_counter[first_word] / words_count\n",
    "    second_word_prob = word_counter[second_word] / words_count\n",
    "    return math.log(bigram_prob / (first_word_prob * second_word_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood_ratio(bigram, *, word_counter, bigrams_counter, words_count, bigrams_count):\n",
    "    first_word, second_word = bigram\n",
    "    k11 = bigrams_counter[bigram] / bigrams_count\n",
    "    k12 = word_counter[second_word] / words_count - k11\n",
    "    k21 = word_counter[first_word] / words_count - k11\n",
    "    k22 = 1 - (k12 + k21 - k11)\n",
    "    matrix = np.matrix([\n",
    "        [k11, k12],\n",
    "        [k21, k22]\n",
    "    ])\n",
    "    return loglikelihood.llr(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_judgment_filenames = glob.glob(PATH)\n",
    "\n",
    "if not os.path.isfile(FILENAMES_FOR_YEAR):\n",
    "    get_filenames_with_judgments_for_year(all_judgment_filenames)\n",
    "\n",
    "with open(FILENAMES_FOR_YEAR) as file:\n",
    "    filenames_with_judgments_for_year = json.load(file)\n",
    "    judgments = itertools.chain.from_iterable(map(get_judgments, filenames_with_judgments_for_year))\n",
    "\n",
    "judgment_texts = (clear_text(judgment['textContent']) for judgment in judgments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(WORD_COUNTS_FILENAME):\n",
    "    counter = Counter(generate_words(judgment_texts))\n",
    "    sorted_counter = dict(sorted(counter.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    with open(WORD_COUNTS_FILENAME, 'w') as file:\n",
    "        json.dump(sorted_counter, file)\n",
    "\n",
    "with open(WORD_COUNTS_FILENAME) as file:\n",
    "    word_counter = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(BIGRAMS_COUNTS_FILENAME):\n",
    "    counter = Counter(generate_bigrams(judgment_texts))\n",
    "    sorted_counter = dict(sorted(counter.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    with open(BIGRAMS_COUNTS_FILENAME, 'w') as file:\n",
    "        json_to_dump = [{'key': key, 'value': value} for key, value in sorted_counter.items()]\n",
    "        json.dump(json_to_dump, file)\n",
    "\n",
    "with open(BIGRAMS_COUNTS_FILENAME) as file:\n",
    "    bigrams_counter = {tuple(item['key']): item['value'] for item in json.load(file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_count = sum(word_counter.values())\n",
    "bigrams_count = sum(bigrams_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_results(bigrams_counter, func):\n",
    "    bigrams_with_func_values = {key: func(key) for key in bigrams_counter}\n",
    "    print(func.func.__name__)\n",
    "    for bigram, func_value in heapq.nlargest(NUMBER_OF_RESULTS, bigrams_with_func_values.items(), key=operator.itemgetter(1)):\n",
    "        print(bigram, func_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pointwise_mutual_information\n",
      "('napawania', 'łukowego') 16.09302540207235\n",
      "('przyjeżdżają', 'mochody') 16.09302540207235\n",
      "('systematycznością', 'stabilnością') 16.09302540207235\n",
      "('osadnika', 'śużla') 16.09302540207235\n",
      "('puhb', 'cewogaz') 16.09302540207235\n",
      "('pre', 'fabrykat') 16.09302540207235\n",
      "('uścikowiec', 'oborniki') 16.09302540207235\n",
      "('transmisjami', 'piłkarskimi') 16.09302540207235\n",
      "('rozjaśnione', 'rozbielone') 16.09302540207235\n",
      "('diagności', 'laboratoryjni') 16.09302540207235\n",
      "('histochemicznych', 'immunopatologicznych') 16.09302540207235\n",
      "('immunopatologicznych', 'mikroskopii') 16.09302540207235\n",
      "('przydomowego', 'ogródka') 16.09302540207235\n",
      "('przetwórcom', 'rybnym') 16.09302540207235\n",
      "('książeczką', 'wkładową') 16.09302540207235\n",
      "('wkładową', 'walutową') 16.09302540207235\n",
      "('walutową', 'książeczka') 16.09302540207235\n",
      "('kobylarnia', 'brzoza') 16.09302540207235\n",
      "('societe', 'anonyme') 16.09302540207235\n",
      "('navigation', 'aerienne') 16.09302540207235\n",
      "('aerienne', 'sabena') 16.09302540207235\n",
      "('receptor', 'frd') 16.09302540207235\n",
      "('niedokrwistości', 'nerkopochodnej') 16.09302540207235\n",
      "('nawracającymi', 'migrenami') 16.09302540207235\n",
      "('connectel', 'airadionet') 16.09302540207235\n",
      "('airadionet', 'bearcoms') 16.09302540207235\n",
      "('mat', 'grubowarstwowymi') 16.09302540207235\n",
      "('ułanowicz', 'świerzbin') 16.09302540207235\n",
      "('destabilizacją', 'zespoleń') 16.09302540207235\n",
      "('wale', 'wiślanym') 16.09302540207235\n"
     ]
    }
   ],
   "source": [
    "func = partial(pointwise_mutual_information, word_counter=word_counter, bigrams_counter=bigrams_counter, \n",
    "              words_count=words_count, bigrams_count=bigrams_count)\n",
    "get_results(bigrams_counter, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood_ratio\n",
      "('z', 'dnia') 0.18531051883654623\n",
      "('zamówień', 'publicznych') 0.14532207123628244\n",
      "('na', 'podstawie') 0.13198481579815652\n",
      "('sygn', 'akt') 0.11827442509884811\n",
      "('ust', 'pkt') 0.1151114664099067\n",
      "('zgodnie', 'z') 0.10711877035704384\n",
      "('sąd', 'najwyższy') 0.1036572114616913\n",
      "('w', 'dniu') 0.09969245989930654\n",
      "('sp', 'z') 0.09783296514906864\n",
      "('trybunał', 'konstytucyjny') 0.09664021601960636\n",
      "('związku', 'z') 0.0960044613352229\n",
      "('gr', 'słownie') 0.0931042117594651\n",
      "('ust', 'ustawy') 0.09273527783356715\n",
      "('sądu', 'najwyższego') 0.09026066773749081\n",
      "('ustawy', 'pzp') 0.08959393587128982\n",
      "('na', 'rzecz') 0.0894411150589385\n",
      "('przez', 'zamawiającego') 0.08931707480307122\n",
      "('w', 'związku') 0.08842643579657747\n",
      "('sądu', 'okręgowego') 0.08691197935424622\n",
      "('sąd', 'okręgowy') 0.08564659055017163\n",
      "('w', 'sprawie') 0.08529106041886966\n",
      "('w', 'postępowaniu') 0.08472758291847376\n",
      "('otk', 'zu') 0.08373242192961379\n",
      "('urzędu', 'zamówień') 0.08328394061297413\n",
      "('zero', 'groszy') 0.08223610834567639\n",
      "('trybunału', 'konstytucyjnego') 0.08129749467058184\n",
      "('prawo', 'zamówień') 0.08075921573719745\n",
      "('sąd', 'apelacyjny') 0.08074191055209315\n",
      "('w', 'tym') 0.08029971940100533\n",
      "('zł', 'gr') 0.07971886639107807\n"
     ]
    }
   ],
   "source": [
    "func = partial(log_likelihood_ratio, word_counter=word_counter, bigrams_counter=bigrams_counter, \n",
    "              words_count=words_count, bigrams_count=bigrams_count)\n",
    "get_results(bigrams_counter, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pointwise_mutual_information\n",
      "('trybunale', 'konstytucyjnym') 8.678131611827096\n",
      "('równego', 'traktowania') 8.518284157328502\n",
      "('punktu', 'widzenia') 8.444136037340279\n",
      "('przede', 'wszystkim') 8.348890641119182\n",
      "('przetargu', 'nieograniczonego') 8.247823342260315\n",
      "('związania', 'ofertą') 8.150378911979955\n",
      "('nakazuje', 'zaliczyć') 8.113752846202376\n",
      "('siedemdziesiąt', 'cztery') 8.06168027418893\n",
      "('działalność', 'gospodarczą') 8.025352473526059\n",
      "('dochodów', 'własnych') 8.02506028661144\n",
      "('rzeczypospolitej', 'polskiej') 7.970345247712421\n",
      "('izbie', 'cywilnej') 7.957234659629259\n",
      "('dalszego', 'biegu') 7.931726960159475\n",
      "('sądów', 'powszechnych') 7.926927000094623\n",
      "('posiedzeniu', 'niejawnym') 7.917434430614341\n",
      "('rachunku', 'dochodów') 7.810191297010222\n",
      "('uczciwej', 'konkurencji') 7.787196262491714\n",
      "('nieuczciwej', 'konkurencji') 7.781557579167587\n",
      "('otk', 'zu') 7.759022601084957\n",
      "('cztery', 'złote') 7.75102660406432\n",
      "('zero', 'groszy') 7.748815740870011\n",
      "('złote', 'zero') 7.728555113649864\n",
      "('ubezpieczeń', 'społecznych') 7.719807112542082\n",
      "('interes', 'prawny') 7.715986984636086\n",
      "('cztery', 'tysiące') 7.706889379955135\n",
      "('dokonać', 'wpłaty') 7.701458922918858\n",
      "('działalności', 'gospodarczej') 7.636490609638732\n",
      "('skargę', 'kasacyjną') 7.583238399536388\n",
      "('skład', 'orzekający') 7.549174060207173\n",
      "('rady', 'ministrów') 7.535847216009389\n"
     ]
    }
   ],
   "source": [
    "func = partial(pointwise_mutual_information, word_counter=word_counter, bigrams_counter=bigrams_counter, \n",
    "              words_count=words_count, bigrams_count=bigrams_count)\n",
    "get_results({key: value for key, value in bigrams_counter.items() if value >= 1000}, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
