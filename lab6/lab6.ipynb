{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter, namedtuple, defaultdict\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir_if_doesnt_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "YEAR = 2009\n",
    "PATH = 'F:\\\\saos\\\\data\\\\json\\\\judgments-*'\n",
    "RESULTS_DIR = 'results'\n",
    "HELPERS_DIR = 'helpers'\n",
    "\n",
    "create_dir_if_doesnt_exist(RESULTS_DIR)\n",
    "create_dir_if_doesnt_exist(HELPERS_DIR)\n",
    "\n",
    "FILENAMES_FOR_YEAR = os.path.join(HELPERS_DIR, f'judgments_from_{YEAR}.json')\n",
    "WORD_COUNTS_FILENAME = os.path.join(HELPERS_DIR, f'word_counts_{YEAR}.json')\n",
    "TAGGED_TEXTS = os.path.join(HELPERS_DIR, f'tagged_texts_{YEAR}.pkl')\n",
    "NUMBER_OF_RESULTS = 30\n",
    "TEST_SIZE = 0.25\n",
    "TAGGER_SERVER_URL = 'http://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_pattern = str(YEAR) + '-\\d{2}-\\d{2}'\n",
    "\n",
    "\n",
    "def get_filenames_with_judgments_for_year(judgment_filenames):\n",
    "    with open(FILENAMES_FOR_YEAR, 'w') as file:\n",
    "        filenames_for_year = filter(contains_judgments_from_year, judgment_filenames)\n",
    "        json.dump(list(filenames_for_year), file)\n",
    "\n",
    "\n",
    "def contains_judgments_from_year(filename):\n",
    "    return any(re.match(year_pattern, item['judgmentDate']) for item in get_judgments(filename))\n",
    "\n",
    "\n",
    "def get_judgments(filename):\n",
    "    with open(filename, encoding='utf-8') as file:\n",
    "        content = json.load(file)\n",
    "    return (item for item in content['items']\n",
    "            if re.match(year_pattern, item['judgmentDate']) and item['courtType'].upper() in ('COMMON', 'SUPREME')\n",
    "            and 'Uzasadnienie' in item['textContent'])\n",
    "\n",
    "\n",
    "def clear_text(text: str, most_common_words, is_original=True):  # False for tagged texts\n",
    "    start_word = 'Uzasadnienie' if is_original else 'uzasadnienie'\n",
    "    text = skip_part_before(text, start_word)\n",
    "    html_clear_text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    return ' '.join(filter(\n",
    "        lambda word: word not in most_common_words,\n",
    "        tokenize(re.sub('-\\n', '', html_clear_text)))\n",
    "    )\n",
    "\n",
    "\n",
    "def skip_part_before(text, start_word):\n",
    "    start_word_index = text.find(start_word) + len(start_word) + 1\n",
    "    return text[start_word_index:]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    yield from filter(is_word, map(str.lower, nltk.word_tokenize(text, language='polish')))\n",
    "\n",
    "    \n",
    "def is_word(word: str):\n",
    "    return word.isalpha() and len(word) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TaggingResult = namedtuple('TaggingResult', 'word tag')\n",
    "\n",
    "\n",
    "def generate_unigrams_from_response(response):\n",
    "    for line in response.split('\\n'):\n",
    "        if not line.startswith('\\t'):\n",
    "            continue\n",
    "        _, word, tags, _ = line.split('\\t')\n",
    "        tag = tags.split(':')[0]\n",
    "        yield TaggingResult(word.lower(), tag)\n",
    "\n",
    "        \n",
    "def generate_tagged_texts(judgments):\n",
    "    texts = map(operator.itemgetter('textContent'), judgments)\n",
    "    for index, judgment_text in enumerate(texts):\n",
    "        print(index)\n",
    "        resp = requests.post(TAGGER_SERVER_URL, data=judgment_text.encode('utf-8'))\n",
    "        if not resp.ok:\n",
    "            yield None\n",
    "        else:\n",
    "            result = ' '.join(map(operator.attrgetter('word'), generate_unigrams_from_response(resp.text)))\n",
    "            with open(os.path.join('tagged', f'{index}.txt'), 'w', encoding='utf-8') as file:\n",
    "                file.write(result)\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_judgment_filenames = glob.glob(PATH)\n",
    "\n",
    "if not os.path.isfile(FILENAMES_FOR_YEAR):\n",
    "    get_filenames_with_judgments_for_year(all_judgment_filenames)\n",
    "\n",
    "with open(FILENAMES_FOR_YEAR) as file:\n",
    "    filenames_with_judgments_for_year = json.load(file)\n",
    "    judgments = list(itertools.chain.from_iterable(map(get_judgments, filenames_with_judgments_for_year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(TAGGED_TEXTS):    \n",
    "    tagged_judgment_texts = list(generate_tagged_texts(judgments))\n",
    "    with open(TAGGED_TEXTS, 'wb') as file:\n",
    "        pickle.dump(tagged_judgment_texts, file)\n",
    "        \n",
    "with open(TAGGED_TEXTS, 'rb') as file:\n",
    "    tagged_judgment_texts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None in tagged_judgment_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "judgments = list(itertools.compress(judgments, tagged_judgment_texts))\n",
    "tagged_judgment_texts = [text for text in tagged_judgment_texts if text is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_counter():\n",
    "    with open(WORD_COUNTS_FILENAME) as file:\n",
    "        word_counter = Counter(json.load(file))\n",
    "    return word_counter\n",
    "\n",
    "\n",
    "def get_most_common_words(k=20):\n",
    "    counter = get_words_counter()\n",
    "    return list(map(operator.itemgetter(0), counter.most_common(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common_words = get_most_common_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w',\n",
       " 'z',\n",
       " 'i',\n",
       " 'na',\n",
       " 'do',\n",
       " 'nie',\n",
       " 'o',\n",
       " 'że',\n",
       " 'przez',\n",
       " 'ust',\n",
       " 'się',\n",
       " 'dnia',\n",
       " 'jest',\n",
       " 'a',\n",
       " 'oraz',\n",
       " 'ustawy',\n",
       " 'od',\n",
       " 'sąd',\n",
       " 'nr',\n",
       " 'postępowania']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Text = namedtuple('Text', ['original_form', 'base_form'])\n",
    "\n",
    "\n",
    "def extract_signature(item):\n",
    "    signature = item['courtCases'][0]['caseNumber'].split(' ')\n",
    "    if len(signature) == 2:\n",
    "        return signature[0]\n",
    "    return signature[1]\n",
    "    \n",
    "    \n",
    "def get_group(signature):\n",
    "    # A?C.* - sprawy cywilne\n",
    "    # A?U.* - sprawy z zakresu ubezpieczenia społecznego\n",
    "    # A?K.* - sprawy karne\n",
    "    # G.* - sprawy gospodarcze\n",
    "    # A?P.* - sprawy w zakresie prawa pracy\n",
    "    # R.* - sprawy w zakresie prawa rodzinnego\n",
    "    # W.* - sprawy o wykroczenia\n",
    "    # Am.* - sprawy w zakresie prawa konkurencji\n",
    "    regexes = {\n",
    "        'civil': 'A?C.*',\n",
    "        'social_security': 'A?U.*',\n",
    "        'penal': 'A?K.*',\n",
    "        'economy': 'G.*',\n",
    "        'employment': 'A?P.*',\n",
    "        'family': 'R.*',\n",
    "        'offence': 'W.*',\n",
    "        'competition': 'Am.*'\n",
    "    }\n",
    "    for case_type, regex in regexes.items():\n",
    "        if re.match(regex, signature):\n",
    "            return case_type\n",
    "    return None\n",
    "\n",
    "def create_groups(judgments, tagged_judgment_texts, most_common_words):\n",
    "    groups = defaultdict(list)\n",
    "    unmatched = 0\n",
    "    for judgment, tagged_judgment_text in zip(judgments, tagged_judgment_texts):\n",
    "        signature = extract_signature(judgment)\n",
    "        group = get_group(signature)\n",
    "        if group:\n",
    "            original_form_text = clear_text(judgment['textContent'], most_common_words)\n",
    "            base_form_text = clear_text(tagged_judgment_text, most_common_words, is_original=False)      \n",
    "            groups[group].append(Text(original_form_text, base_form_text))\n",
    "        else:\n",
    "            unmatched += 1\n",
    "            print('Group not found for', signature, judgment['courtCases'])\n",
    "    print(unmatched, 'unmatched judgments')\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group not found for SNO [{'caseNumber': 'SNO 25/09'}]\n",
      "Group not found for SNO [{'caseNumber': 'SNO 10/09'}]\n",
      "Group not found for SPP [{'caseNumber': 'III SPP 14/09'}]\n",
      "Group not found for SK [{'caseNumber': 'III SK 4/09'}]\n",
      "Group not found for SK [{'caseNumber': 'III SK 5/09'}]\n",
      "Group not found for SNO [{'caseNumber': 'SNO 59/09'}]\n",
      "Group not found for BU [{'caseNumber': 'I BU 10/09'}]\n",
      "Group not found for SNO [{'caseNumber': 'SNO 88/09'}]\n",
      "Group not found for BP [{'caseNumber': 'II BP 12/09'}]\n",
      "Group not found for SK [{'caseNumber': 'III SK 30/09'}]\n",
      "Group not found for SK [{'caseNumber': 'III SK 34/09'}]\n",
      "Group not found for SK [{'caseNumber': 'III SK 36/09'}]\n",
      "12 unmatched judgments\n"
     ]
    }
   ],
   "source": [
    "groups = create_groups(judgments, tagged_judgment_texts, most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social_security 66\n",
      "employment 85\n",
      "civil 1439\n",
      "penal 12\n"
     ]
    }
   ],
   "source": [
    "for case_type, texts in groups.items():\n",
    "    print(case_type, len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment 181\n",
      "civil 1662\n",
      "social_security 224\n",
      "penal 17\n",
      "competition 3\n"
     ]
    }
   ],
   "source": [
    "# load groups dict for judgments from 2010 to get better classification results\n",
    "with open(os.path.join(HELPERS_DIR, 'groups_2010.pkl'), 'rb') as file:\n",
    "    groups_2010 = pickle.load(file)\n",
    "    \n",
    "for case_type, texts in groups_2010.items():\n",
    "    print(case_type, len(texts))\n",
    "    groups[case_type].extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = {case_type: texts for case_type, texts in groups.items() if len(texts) > 99}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "social_security 290\n",
      "employment 266\n",
      "civil 3101\n"
     ]
    }
   ],
   "source": [
    "for case_type, texts in groups.items():\n",
    "    print(case_type, len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3657"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(texts) for texts in groups.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(y_test, predictions, average):\n",
    "    print(average, 'average')\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, predictions, average=average)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1:', f1)\n",
    "\n",
    "    \n",
    "def train_classifiers(x_train, x_test, y_train, y_test, form):\n",
    "    assert form in ('original_form', 'base_form')\n",
    "    train_x = [getattr(text, form) for text in x_train]\n",
    "    test_x = [getattr(text, form) for text in x_test]\n",
    "    for group, group_texts in groups.items():\n",
    "        classifier = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "        ])\n",
    "        train_y = [int(y == group) for y in y_train]\n",
    "        test_y = [int(y == group) for y in y_test]\n",
    "        classifier.fit(train_x, train_y)\n",
    "        predictions = classifier.predict(test_x)\n",
    "        print('Group:', group)\n",
    "        print('Group size:', sum(len(getattr(text, form).split(' ')) for text in group_texts), 'words')\n",
    "        print_results(test_y, predictions, average='micro')\n",
    "        print_results(test_y, predictions, average='macro')\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = list(itertools.chain.from_iterable([case_type for _ in range(len(texts))] for case_type, texts in groups.items())) \n",
    "judgment_texts = list(itertools.chain.from_iterable(texts for texts in groups.values()))\n",
    "x_train, x_test, y_train, y_test = train_test_split(judgment_texts, labels, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts\n",
      "Group: social_security\n",
      "Group size: 360409 words\n",
      "micro average\n",
      "Precision: 0.9901639344262295\n",
      "Recall: 0.9901639344262295\n",
      "F1: 0.9901639344262295\n",
      "macro average\n",
      "Precision: 0.9774241414814366\n",
      "Recall: 0.9616139138582263\n",
      "F1: 0.9693534641563922\n",
      "\n",
      "\n",
      "Group: employment\n",
      "Group size: 495362 words\n",
      "micro average\n",
      "Precision: 0.9715846994535519\n",
      "Recall: 0.9715846994535519\n",
      "F1: 0.9715846994535519\n",
      "macro average\n",
      "Precision: 0.9578282378108566\n",
      "Recall: 0.8384984183471729\n",
      "F1: 0.8875411261959687\n",
      "\n",
      "\n",
      "Group: civil\n",
      "Group size: 2574854 words\n",
      "micro average\n",
      "Precision: 0.9770491803278688\n",
      "Recall: 0.9770491803278688\n",
      "F1: 0.9770491803278688\n",
      "macro average\n",
      "Precision: 0.9804899330118402\n",
      "Recall: 0.9369976278649077\n",
      "F1: 0.9570949136874258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original texts')\n",
    "train_classifiers(x_train, x_test, y_train, y_test, form='original_form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged texts\n",
      "Group: social_security\n",
      "Group size: 414021 words\n",
      "micro average\n",
      "Precision: 0.9923497267759562\n",
      "Recall: 0.9923497267759562\n",
      "F1: 0.9923497267759562\n",
      "macro average\n",
      "Precision: 0.9843513415298892\n",
      "Recall: 0.9683117149298743\n",
      "F1: 0.9761638054549717\n",
      "\n",
      "\n",
      "Group: employment\n",
      "Group size: 561540 words\n",
      "micro average\n",
      "Precision: 0.9748633879781421\n",
      "Recall: 0.9748633879781421\n",
      "F1: 0.9748633879781421\n",
      "macro average\n",
      "Precision: 0.9689511009937399\n",
      "Recall: 0.8529804270462633\n",
      "F1: 0.9012551319648094\n",
      "\n",
      "\n",
      "Group: civil\n",
      "Group size: 2993096 words\n",
      "micro average\n",
      "Precision: 0.9814207650273225\n",
      "Recall: 0.9814207650273225\n",
      "F1: 0.9814207650273225\n",
      "macro average\n",
      "Precision: 0.9832178789378195\n",
      "Recall: 0.9499846408519208\n",
      "F1: 0.9656489813945784\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Tagged texts')\n",
    "train_classifiers(x_train, x_test, y_train, y_test, form='base_form')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
